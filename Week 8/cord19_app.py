# ============================================================
# CORD-19 Research Data Analysis and Streamlit Application
# ============================================================

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import streamlit as st

# -----------------------------
# SETUP: Kaggle API Download
# -----------------------------
# REQUIREMENT:
# You must have a Kaggle account and your Kaggle API key file (kaggle.json)
# stored in ~/.kaggle/kaggle.json or provide it using Streamlit input.

# This script uses Kaggleâ€™s API to download metadata.csv automatically.

# -----------------------------
# Streamlit UI Setup
# -----------------------------
st.title("CORD-19 Data Explorer (Auto Kaggle Fetch)")
st.write("An interactive web app to explore COVID-19 research data from the CORD-19 dataset on Kaggle.")

# User provides Kaggle credentials (optional if already configured)
kaggle_username = st.text_input("Enter Kaggle Username (optional)", "")
kaggle_key = st.text_input("Enter Kaggle API Key (optional)", "", type="password")

# -----------------------------
# Function: Download dataset
# -----------------------------
@st.cache_data
def download_cord19_data(user=None, key=None):
    import subprocess

    if user and key:
        os.makedirs(os.path.expanduser("~/.kaggle"), exist_ok=True)
        with open(os.path.expanduser("~/.kaggle/kaggle.json"), "w") as f:
            f.write(f'{{"username":"{user}","key":"{key}"}}')
        os.chmod(os.path.expanduser("~/.kaggle/kaggle.json"), 0o600)

    dataset = "allen-institute-for-ai/CORD-19-research-challenge"
    dest_dir = "cord19_data"
    os.makedirs(dest_dir, exist_ok=True)

    subprocess.run(
        ["kaggle", "datasets", "download", "-d", dataset, "-p", dest_dir, "--unzip"],
        check=True
    )

    file_path = os.path.join(dest_dir, "metadata.csv")
    return file_path

# -----------------------------
# Load the dataset
# -----------------------------
try:
    file_path = "cord19_data/metadata.csv"
    if not os.path.exists(file_path):
        st.info("Downloading dataset from Kaggle... please wait (may take a few minutes)")
        file_path = download_cord19_data(kaggle_username, kaggle_key)
        st.success("Dataset downloaded successfully!")

    df = pd.read_csv(file_path, low_memory=False)
    st.success(" Dataset loaded successfully!")
except Exception as e:
    st.error(f"Failed to load dataset: {e}")
    st.stop()

# -----------------------------
# Basic Exploration
# -----------------------------
st.subheader("Basic Data Overview")
st.write(f"Rows: {df.shape[0]}, Columns: {df.shape[1]}")
st.dataframe(df.head())

# -----------------------------
# Data Cleaning & Preparation
# -----------------------------
df['publish_time'] = pd.to_datetime(df['publish_time'], errors='coerce')
df['year'] = df['publish_time'].dt.year
df['abstract_word_count'] = df['abstract'].fillna('').apply(lambda x: len(x.split()))
df_clean = df.dropna(subset=['title', 'publish_time'])

# -----------------------------
# Sidebar Filters
# -----------------------------
st.sidebar.header("ğŸ”§ Filters")
min_year, max_year = int(df_clean['year'].min()), int(df_clean['year'].max())
year_range = st.sidebar.slider("Select Year Range", min_year, max_year, (2020, 2021))
filtered_df = df_clean[(df_clean['year'] >= year_range[0]) & (df_clean['year'] <= year_range[1])]

# -----------------------------
# Visualizations
# -----------------------------
st.subheader("Publications Over Time")
year_counts = filtered_df['year'].value_counts().sort_index()
fig1, ax1 = plt.subplots()
ax1.bar(year_counts.index, year_counts.values)
ax1.set_xlabel("Year")
ax1.set_ylabel("Number of Publications")
ax1.set_title("COVID-19 Research Publications by Year")
st.pyplot(fig1)

st.subheader(" Top Journals")
top_journals = filtered_df['journal'].value_counts().head(10).sort_values(ascending=True)
fig2, ax2 = plt.subplots()
top_journals.plot(kind='barh', ax=ax2)
ax2.set_xlabel("Number of Papers")
ax2.set_ylabel("Journal")
ax2.set_title("Top 10 Publishing Journals")
st.pyplot(fig2)

st.subheader(" Word Cloud of Paper Titles")
text = " ".join(filtered_df['title'].dropna().tolist())
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
fig3, ax3 = plt.subplots()
ax3.imshow(wordcloud, interpolation='bilinear')
ax3.axis("off")
st.pyplot(fig3)

st.subheader("Paper Source Distribution")
fig4, ax4 = plt.subplots()
filtered_df['source_x'].value_counts().head(10).plot(kind='bar', ax=ax4)
ax4.set_title("Top 10 Sources of Papers")
ax4.set_xlabel("Source")
ax4.set_ylabel("Count")
st.pyplot(fig4)

# -----------------------------
# Display Cleaned Data
# -----------------------------
st.subheader("ğŸ“‹ Sample of Cleaned Data")
st.dataframe(filtered_df[['title', 'journal', 'year', 'abstract_word_count']].head(15))

# -----------------------------
# Reflection
# -----------------------------
st.subheader("ğŸ§­ Key Insights")
st.write("""
- The research publication surge occurred mainly in **2020 and 2021** during peak pandemic years.
- Journals like *Nature*, *The Lancet*, and *BMJ* feature prominently.
- Common words in titles reflect pandemic-related themes: "COVID-19", "SARS-CoV-2", "infection", "patients".
""")

st.info("This interactive dashboard demonstrates real-world data loading, cleaning, and visualization using Python and Streamlit â€” fully automated via Kaggleâ€™s API!")

